{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-cased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_BBPC = BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")\n",
    "tokenizer_BBPC = BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")\n",
    "\n",
    "model_HBC = AutoModelWithLMHead.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "tokenizer_HBC = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "\n",
    "model_HLC = AutoModelWithLMHead.from_pretrained(\"allegro/herbert-large-cased\")\n",
    "tokenizer_HLC = AutoTokenizer.from_pretrained(\"allegro/herbert-large-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_with_tokenizers = {\"dkleczek/bert-base-polish-cased-v1\": (model_BBPC, tokenizer_BBPC),\n",
    "                          \"allegro/herbert-base-cased\": (model_HBC, tokenizer_HBC),\n",
    "                          \"allegro/herbert-large-cased\": (model_HLC, tokenizer_HLC)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_top_predictions(sentences, top_num, mask_end=True):\n",
    "    for name, model_tokenizer in models_with_tokenizers.items():\n",
    "        model = model_tokenizer[0]\n",
    "        tokenizer = model_tokenizer[1]\n",
    "\n",
    "        print(\"Model name: {}\".format(name))\n",
    "        for sentence in sentences:\n",
    "            if mask_end:\n",
    "                sentence = sentence + \"{}\".format(tokenizer.mask_token) + \".\"\n",
    "            else:\n",
    "                sentence = sentence.replace(\"[MASK]\", tokenizer.mask_token)\n",
    "\n",
    "            print(\"\\t\" + sentence)\n",
    "\n",
    "            input = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "            mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "\n",
    "            token_logits = model(input, return_dict=True).logits\n",
    "            mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "            top_5_tokens = torch.topk(mask_token_logits, top_num, dim=1).indices[0].tolist()\n",
    "            for i, token in enumerate(top_5_tokens):\n",
    "                print(\"\\t\\t{} : {}\".format(i+1, tokenizer.decode([token])))\n",
    "                i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: dkleczek/bert-base-polish-cased-v1\n",
      "\tWarszawa to największe [MASK].\n",
      "\t\t1 : miasto\n",
      "\t\t2 : województwo\n",
      "\t\t3 : lotnisko\n",
      "\t\t4 : miasteczko\n",
      "\t\t5 : państwo\n",
      "\tTe zabawki należą do [MASK].\n",
      "\t\t1 : ciebie\n",
      "\t\t2 : mnie\n",
      "\t\t3 : nas\n",
      "\t\t4 : pana\n",
      "\t\t5 : niego\n",
      "\tPolicjant przygląda się [MASK].\n",
      "\t\t1 : temu\n",
      "\t\t2 : sprawie\n",
      "\t\t3 : im\n",
      "\t\t4 : wszystkiemu\n",
      "\t\t5 : panu\n",
      "\tNa środku skrzyżowania widać [MASK].\n",
      "\t\t1 : rzekę\n",
      "\t\t2 : ulicę\n",
      "\t\t3 : drzewa\n",
      "\t\t4 : drogę\n",
      "\t\t5 : las\n",
      "\tWłaściciel samochodu widział złodzieja z [MASK].\n",
      "\t\t1 : bronią\n",
      "\t\t2 : tyłu\n",
      "\t\t3 : ulicy\n",
      "\t\t4 : bliska\n",
      "\t\t5 : zewnątrz\n",
      "\tPrezydent z premierem rozmawiali wczoraj o [MASK].\n",
      "\t\t1 : tym\n",
      "\t\t2 : Polsce\n",
      "\t\t3 : budżecie\n",
      "\t\t4 : ASF\n",
      "\t\t5 : ustawie\n",
      "\tWitaj drogi [MASK].\n",
      "\t\t1 : chłopcze\n",
      "\t\t2 : przyjacielu\n",
      "\t\t3 : bracie\n",
      "\t\t4 : kolego\n",
      "\t\t5 : synu\n",
      "Model name: allegro/herbert-base-cased\n",
      "\tWarszawa to największe <mask>.\n",
      "\t\t1 : miasto\n",
      "\t\t2 : lotnisko\n",
      "\t\t3 : centrum\n",
      "\t\t4 : miasta\n",
      "\t\t5 : atrakcje\n",
      "\tTe zabawki należą do <mask>.\n",
      "\t\t1 : rodziny\n",
      "\t\t2 : nas\n",
      "\t\t3 : nich\n",
      "\t\t4 : najlepszych\n",
      "\t\t5 : .\n",
      "\tPolicjant przygląda się <mask>.\n",
      "\t\t1 : mężczyźnie\n",
      "\t\t2 : kobiecie\n",
      "\t\t3 : mu\n",
      "\t\t4 : dziewczynie\n",
      "\t\t5 : sprawie\n",
      "\tNa środku skrzyżowania widać <mask>.\n",
      "\t\t1 : rondo\n",
      "\t\t2 : samochody\n",
      "\t\t3 : radiowóz\n",
      "\t\t4 : samochód\n",
      "\t\t5 : wiadukt\n",
      "\tWłaściciel samochodu widział złodzieja z <mask>.\n",
      "\t\t1 : samochodu\n",
      "\t\t2 : włamaniem\n",
      "\t\t3 : auta\n",
      "\t\t4 : kierowcą\n",
      "\t\t5 : parkingu\n",
      "\tPrezydent z premierem rozmawiali wczoraj o <mask>.\n",
      "\t\t1 : przyszłości\n",
      "\t\t2 : Polsce\n",
      "\t\t3 : bezpieczeństwie\n",
      "\t\t4 : polityce\n",
      "\t\t5 : Warszawie\n",
      "\tWitaj drogi <mask>.\n",
      "\t\t1 : Łukasz\n",
      "\t\t2 : Boże\n",
      "\t\t3 : człowieku\n",
      "\t\t4 : Karol\n",
      "\t\t5 : Marcin\n",
      "Model name: allegro/herbert-large-cased\n",
      "\tWarszawa to największe <mask>.\n",
      "\t\t1 : miasto\n",
      "\t\t2 : miasta\n",
      "\t\t3 : .\n",
      "\t\t4 : lotnisko\n",
      "\t\t5 : miast\n",
      "\tTe zabawki należą do <mask>.\n",
      "\t\t1 : dzieci\n",
      "\t\t2 : mnie\n",
      "\t\t3 : nas\n",
      "\t\t4 : najmłodszych\n",
      "\t\t5 : Ciebie\n",
      "\tPolicjant przygląda się <mask>.\n",
      "\t\t1 : sprawie\n",
      "\t\t2 : sytuacji\n",
      "\t\t3 : zdarzeniu\n",
      "\t\t4 : wszystkiemu\n",
      "\t\t5 : kobiecie\n",
      "\tNa środku skrzyżowania widać <mask>.\n",
      "\t\t1 : rondo\n",
      "\t\t2 : krzyż\n",
      "\t\t3 : radiowóz\n",
      "\t\t4 : samochód\n",
      "\t\t5 : znak\n",
      "\tWłaściciel samochodu widział złodzieja z <mask>.\n",
      "\t\t1 : bronią\n",
      "\t\t2 : bliska\n",
      "\t\t3 : kamerą\n",
      "\t\t4 : nożem\n",
      "\t\t5 : kamery\n",
      "\tPrezydent z premierem rozmawiali wczoraj o <mask>.\n",
      "\t\t1 : tym\n",
      "\t\t2 : sprawie\n",
      "\t\t3 : sytuacji\n",
      "\t\t4 : prywatyzacji\n",
      "\t\t5 : .\n",
      "\tWitaj drogi <mask>.\n",
      "\t\t1 : człowieku\n",
      "\t\t2 : Panie\n",
      "\t\t3 : Jezu\n",
      "\t\t4 : panie\n",
      "\t\t5 : misiu\n"
     ]
    }
   ],
   "source": [
    "#zad 3 \n",
    "sentences = [\"Warszawa to największe \", \"Te zabawki należą do \", \"Policjant przygląda się \",\n",
    "             \"Na środku skrzyżowania widać \", \"Właściciel samochodu widział złodzieja z \", \n",
    "             \"Prezydent z premierem rozmawiali wczoraj o \", \"Witaj drogi \"]\n",
    "\n",
    "display_top_predictions(sentences, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: dkleczek/bert-base-polish-cased-v1\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie [MASK].\n",
      "\t\t1 : zgodził\n",
      "\t\t2 : dowiedział\n",
      "\t\t3 : martwił\n",
      "\t\t4 : bał\n",
      "\t\t5 : zabił\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie  [MASK].\n",
      "\t\t1 : zgodziła\n",
      "\t\t2 : bała\n",
      "\t\t3 : dowiedziała\n",
      "\t\t4 : zabiła\n",
      "\t\t5 : pojawiła\n",
      "Model name: allegro/herbert-base-cased\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie <mask>.\n",
      "\t\t1 : zdziwił\n",
      "\t\t2 : poddał\n",
      "\t\t3 : dowiedział\n",
      "\t\t4 : zastanawiał\n",
      "\t\t5 : przyznał\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie  <mask>.\n",
      "\t\t1 : dowiedziała\n",
      "\t\t2 : przyznała\n",
      "\t\t3 : bała\n",
      "\t\t4 : śmiała\n",
      "\t\t5 : zmieniła\n",
      "Model name: allegro/herbert-large-cased\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie <mask>.\n",
      "\t\t1 : bał\n",
      "\t\t2 : poddał\n",
      "\t\t3 : zabił\n",
      "\t\t4 : śmiał\n",
      "\t\t5 : zastanawiał\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie  <mask>.\n",
      "\t\t1 : bała\n",
      "\t\t2 : zgodziła\n",
      "\t\t3 : dowiedziała\n",
      "\t\t4 : zmieniła\n",
      "\t\t5 : śmiała\n"
     ]
    }
   ],
   "source": [
    "#zad 4\n",
    "sentences = [\"Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie \",\n",
    "             \"Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie  \"]\n",
    "display_top_predictions(sentences, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: dkleczek/bert-base-polish-cased-v1\n",
      "\t[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\t\t1 : Woda\n",
      "\t\t2 : Mięso\n",
      "\t\t3 : Słońce\n",
      "\t\t4 : Nie\n",
      "\t\t5 : Piwo\n",
      "\tW wakacje odwiedziłem [MASK], który jest stolicą Islandii.\n",
      "\t\t1 : kraj\n",
      "\t\t2 : Cypr\n",
      "\t\t3 : Meksyk\n",
      "\t\t4 : Gibraltar\n",
      "\t\t5 : Wellington\n",
      "\tInformatyka na [MASK] należy do najlepszych kierunków w Polsce.\n",
      "\t\t1 : wsi\n",
      "\t\t2 : świecie\n",
      "\t\t3 : żywo\n",
      "\t\t4 : pewno\n",
      "\t\t5 : odległość\n",
      "Model name: allegro/herbert-base-cased\n",
      "\t<mask> wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\t\t1 : Woda\n",
      "\t\t2 : Słońce\n",
      "\t\t3 : Ziemia\n",
      "\t\t4 : Następnie\n",
      "\t\t5 : Ciało\n",
      "\tW wakacje odwiedziłem <mask>, który jest stolicą Islandii.\n",
      "\t\t1 : Kraków\n",
      "\t\t2 : Oslo\n",
      "\t\t3 : Londyn\n",
      "\t\t4 : Gdańsk\n",
      "\t\t5 : Toruń\n",
      "\tInformatyka na <mask> należy do najlepszych kierunków w Polsce.\n",
      "\t\t1 : pewno\n",
      "\t\t2 : AGH\n",
      "\t\t3 : UW\n",
      "\t\t4 : studiach\n",
      "\t\t5 : UMK\n",
      "Model name: allegro/herbert-large-cased\n",
      "\t<mask> wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\t\t1 : Woda\n",
      "\t\t2 : Krew\n",
      "\t\t3 : woda\n",
      "\t\t4 : Ogień\n",
      "\t\t5 : Nie\n",
      "\tW wakacje odwiedziłem <mask>, który jest stolicą Islandii.\n",
      "\t\t1 : Oslo\n",
      "\t\t2 : Londyn\n",
      "\t\t3 : Liverpool\n",
      "\t\t4 : Glasgow\n",
      "\t\t5 : Birmingham\n",
      "\tInformatyka na <mask> należy do najlepszych kierunków w Polsce.\n",
      "\t\t1 : AGH\n",
      "\t\t2 : UW\n",
      "\t\t3 : UJ\n",
      "\t\t4 : UAM\n",
      "\t\t5 : uczelni\n"
     ]
    }
   ],
   "source": [
    "#zad 5\n",
    "sentences = [\"[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\",\n",
    "             \"W wakacje odwiedziłem [MASK], który jest stolicą Islandii.\",\n",
    "             \"Informatyka na [MASK] należy do najlepszych kierunków w Polsce.\"]\n",
    "\n",
    "display_top_predictions(sentences, 5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Which of the models produced the best results?***\n",
    "* Każdy z modeli radził sobie lepiej lub gorzej w zależności od konretnego zdania. \n",
    "* Np. w zdaniu \"Informatyka na <mask> należy do najlepszych kierunków w Polsce.\" modele allegro/herbert-large-cased, allegro/herbert-base-cased znalazły nazwy polskich uczelni w przeciwieńśtwie do dkleczek/bert-base-polish-cased-v1.\n",
    "* W zdaniu \"Witaj drogi <mask>.\" model HBC jako jedyny nie poradził sobie z wołaczem i zwrócił nieodmienione polskie imiona. \n",
    "* Model Bert i HLC poradziły sobie dobrze ze zdaniem \"Właściciel samochodu widział złodzieja z [MASK]\", gdzie przewidywały takie słowa jak bronią, nożem. \n",
    "* Trudno, więc podać jedną nazwę modelu, chociaż model dkleczek/bert-base-polish-cased-v1 miał tę przewagę, że nigdy nie przewidział '.' w przeciwieństwie do pozostałych modeli.\n",
    "    \n",
    "***Was any of the models able to capture Polish grammar?***\n",
    "* W zadaniu 4 wszystkie modele poradziły sobie z rozróżnieniem rodzaju żeńskiego do męskiego. \n",
    "* Natomiast analizując zdanie \"Warszawa to największe [MASK].\", tylko model Bert zwrócił wszystkie słowa w liczbie pojedynczej.\n",
    "* Model allegro/herbert-base-cased nie poradził sobie z rozpoznaniem wołacza. \n",
    "* Wydaje się, że model dkleczek/bert-base-polish-cased-v1 najtrafniej poradził sobie z rozpoznaniem polskiej gramatyki.\n",
    "    \n",
    "***Was any of the models able to capture long-distant relationships between the words?***\n",
    "* Modelom allegro/herbert-large-cased, allegro/herbert-base-cased udało się powiązać nazwy polskich uczelni ze słowem informatyka oraz m.in. oddalonym słowem 'Polsce'.\n",
    "* W zdaniu \"W wakacje odwiedziłem <mask>, który jest stolicą Islandii.\", wszystkie modele pozwiązały jakąś nazwę miasta ze \"stolicą Islandii\" (chociaż niekoniecznie trafnie). \n",
    "*W zdaniu \"Prezydent z premierem rozmawiali wczoraj o <mask>.\" pierwsze dwa modele (chociaż drugi trochę lepiej) dobrze poradziły sobie z powiązaniem ostatniego słowa z tematyką policztyczną (za którą odpowiadają pierwsze słowa w zdaniu).\n",
    "    \n",
    "***Was any of the models able to capture world knowledge?***\n",
    "* Tak, np. w zdaniu \"[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\" wszystkie modele rozpoznały, że chodzi o wodę. \n",
    "* Chociaż żaden z nich nie odgadł prawdiłowo stolicy Islandii. \n",
    "* Natomiast w zdaniu \"Informatyka na [MASK] należy do najlepszych kierunków w Polsce.\" dwa ostatnie modele uchwyciły wiedzę dziedzinową.\n",
    "   \n",
    "***What are the most striking errors made by the models?***\n",
    "* Predykcja kropki, mimo tego, że widocznie oczekujemy kolejnego słowa.\n",
    "* Predykcje pierwszego modelu dla zdania \"Informatyka na [MASK] należy do najlepszych kierunków w Polsce.\" (zwrócenie wsi, żywo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
