{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from spacy.lang.pl import Polish\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(Polish().vocab)\n",
    "\n",
    "data_path = '../dane'\n",
    "files = [f for f in listdir(data_path) if isfile(join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097691"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zad 2\n",
    "single_grams = {}\n",
    "bigrams = {}\n",
    "trigrams = {}\n",
    "\n",
    "for filename in files:\n",
    "    file = None\n",
    "    with open(data_path +'/' + filename, 'r', encoding = 'utf-8') as f:\n",
    "        file = f.read().lower()\n",
    "\n",
    "    tokens = tokenizer(file)\n",
    "    \n",
    "    for i in range(len(tokens)-1):\n",
    "        token1 = tokens[i].text\n",
    "        token2 = tokens[i + 1].text\n",
    "        \n",
    "        single_grams[token1] = single_grams.get(token1, 0) + 1\n",
    "        bigram = (token1, token2)\n",
    "        bigrams[bigram] = bigrams.get(bigram, 0) + 1\n",
    "        \n",
    "       \n",
    "    for i in range(len(tokens)-2):\n",
    "        token1 = tokens[i].text\n",
    "        token2 = tokens[i + 1].text\n",
    "        token3 = tokens[i + 2].text\n",
    "        trigram = (token1, token2, token3)\n",
    "\n",
    "        trigrams[trigram] = trigrams.get(trigram, 0) + 1\n",
    "      \n",
    "    last_token = tokens[len(tokens)-1].text\n",
    "    single_grams[last_token] = single_grams.get(last_token, 0) + 1\n",
    "    \n",
    "len(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440588\n"
     ]
    }
   ],
   "source": [
    "#zad3\n",
    "polish_letters = 'aąbcćdeęfghijklłmnńoópqrsśtuvwyxzźż'\n",
    "def only_polish_letters(word):\n",
    "    if len(word) == 0:\n",
    "        return False\n",
    "    for l in word:\n",
    "        if not l in polish_letters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# odfiltrownaie \n",
    "single_grams = {k: v for k,v in single_grams.items() if only_polish_letters(k)}\n",
    "bigrams = {k: v for k,v in bigrams.items() if only_polish_letters(k[0]) and  only_polish_letters(k[1])}\n",
    "print(len(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zad 4\n",
    "total_single_occurances = sum(single_grams.values())\n",
    "total_bigrams_occurances = sum(bigrams.values())\n",
    "bigram_pmi = {}\n",
    "\n",
    "for bigram, freq in bigrams.items():\n",
    "    t1, t2 = bigram\n",
    "    p1 = single_grams[t1]/total_single_occurances\n",
    "    p2 = single_grams[t2]/total_single_occurances\n",
    "    p1p2 = freq/total_bigrams_occurances\n",
    "    pmi = log(p1p2/(p1 * p2))\n",
    "    bigram_pmi[bigram] = (freq, pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('kołowe', 'jednoosiowe'), (1, 15.232429554616882)),\n",
       " (('automatyki', 'grzewczej'), (1, 15.232429554616882)),\n",
       " (('prefabrykatów', 'wnętrzowe'), (1, 15.232429554616882)),\n",
       " (('gołe', 'aluminiowe'), (1, 15.232429554616882)),\n",
       " (('polistyrenu', 'spienionego'), (1, 15.232429554616882)),\n",
       " (('objaśnieniem', 'figur'), (1, 15.232429554616882)),\n",
       " (('wkładzie', 'wnoszonym'), (1, 15.232429554616882)),\n",
       " (('doktorem', 'habilitowanym'), (1, 15.232429554616882)),\n",
       " (('naruszonymi', 'plombami'), (1, 15.232429554616882)),\n",
       " (('zaniedbanej', 'wychowawczo'), (1, 15.232429554616882))]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zad 5\n",
    "bigram_pmi = {k: v for k,v in sorted(bigram_pmi.items(), key=lambda item: item[1][1], reverse=True)}\n",
    "bigram_top_10_pmi = list(bigram_pmi.keys())[:10]\n",
    "list(bigram_pmi.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('świeckie', 'przygotowujące'), (5, 13.622991642182782)),\n",
       " (('ręcznego', 'miotacza'), (5, 13.622991642182782)),\n",
       " (('młyny', 'kulowe'), (5, 13.622991642182782)),\n",
       " (('zaszkodzić', 'wynikom'), (5, 13.622991642182782)),\n",
       " (('grzegorz', 'schetyna'), (5, 13.622991642182782)),\n",
       " (('mleczka', 'makowego'), (5, 13.440670085388827)),\n",
       " (('przeponowe', 'rurowe'), (5, 13.440670085388827)),\n",
       " (('adama', 'mickiewicza'), (6, 13.440670085388827)),\n",
       " (('papierem', 'wartościowym'), (5, 13.28651940556157)),\n",
       " (('chwytów', 'obezwładniających'), (5, 13.28651940556157))]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zad 6\n",
    "bigram_pmi_filtered = {k: v for k,v in bigram_pmi.items() if v[0] >= 5}\n",
    "list(bigram_pmi_filtered.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 7\n",
    "# constructing tree to speedup search\n",
    "def construct_tree(n_grams):\n",
    "    A__tree = {}\n",
    "    _B_tree = {}\n",
    "    for n_gram, freq in n_grams.items():\n",
    "        t_first = n_gram[0]\n",
    "        t_last = n_gram[-1]\n",
    "        t_everything_but_first = n_gram[1:]\n",
    "        #t_everything_but_last = n_gram[:-1]\n",
    "        if len(n_gram) == 2:\n",
    "            t_everything_but_first = t_everything_but_first[0]\n",
    "            #t_everything_but_last = t_everything_but_last[0]\n",
    "            \n",
    "        if t_first not in A__tree:    \n",
    "            A__tree[t_first] = {t_everything_but_first:freq}\n",
    "        if t_everything_but_first not in A__tree[t_first]:\n",
    "            A__tree[t_first][t_everything_but_first] = freq\n",
    "        if t_everything_but_first not in _B_tree:    \n",
    "            _B_tree[t_everything_but_first] = {t_first:freq}\n",
    "        if t_first not in _B_tree[t_everything_but_first]:\n",
    "            _B_tree[t_everything_but_first][t_first] = freq\n",
    "\n",
    "    return A__tree, _B_tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "A__tree, _B_tree = construct_tree(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(vals, N):\n",
    "    res = 0\n",
    "    for val in vals:\n",
    "        val /= N\n",
    "        if not val == 0:\n",
    "            res += val*log(val)\n",
    "    return res\n",
    "\n",
    "def LLR_n_gram(a, b, A__tree, _B_tree):\n",
    "    k11 = A__tree[a][b]\n",
    "    k12 = sum(_B_tree[b].values()) - k11\n",
    "    k21 = sum(A__tree[a].values()) - k11\n",
    "    k22 = total_bigrams_occurances - k11 - k12 - k21\n",
    "    N = k11 + k12 + k21 + k22\n",
    "    return 2 * N * (H([k11,k12,k21,k22], N) - H([k11+k12,k21+k22], N) - H([k11+k21,k12+k22], N))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLR_bigrams  = {k: LLR_n_gram(k[0], k[1], A__tree, _B_tree) for k in bigrams.keys()}\n",
    "bigram_top_10_LLR = list(LLR_bigrams.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('mowa', 'w'), 162056.43970866656),\n",
       " (('których', 'mowa'), 103860.60989464173),\n",
       " (('o', 'których'), 81588.40541168801),\n",
       " (('którym', 'mowa'), 67846.84419746423),\n",
       " (('dodaje', 'się'), 62515.67442178589),\n",
       " (('do', 'spraw'), 57437.651725128424),\n",
       " (('o', 'którym'), 53202.142924775384),\n",
       " (('i', 'nr'), 51618.30513495073),\n",
       " (('z', 'dnia'), 47165.64226194411),\n",
       " (('na', 'podstawie'), 45750.135696047284)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zad 8\n",
    "bigram_top_10_LLR = {k: v for k,v in sorted(LLR_bigrams.items(), key=lambda item: item[1], reverse=True)}\n",
    "list(bigram_top_10_LLR.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zas 9, 10\n",
    "trigrams = {k: v for k,v in trigrams.items() if only_polish_letters(k[0]) and only_polish_letters(k[1]) and only_polish_letters(k[2])}\n",
    "A__trigrams_tree, _B_trigrams_tree = construct_tree(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLR_trigrams  = {k: LLR_n_gram(k[0], k[1:], A__trigrams_tree, _B_trigrams_tree) for k in trigrams.keys()}\n",
    "LLR_trigrams = {k: v for k,v in sorted(LLR_trigrams.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('których', 'mowa', 'w'), 102495.7504384144),\n",
       " (('o', 'których', 'mowa'), 92046.18649791507),\n",
       " (('którym', 'mowa', 'w'), 68036.21581825346),\n",
       " (('o', 'którym', 'mowa'), 62514.58015060082),\n",
       " (('minister', 'właściwy', 'do'), 48241.9150999556),\n",
       " (('właściwy', 'do', 'spraw'), 47786.77952740153),\n",
       " (('której', 'mowa', 'w'), 38775.47991226523),\n",
       " (('ustawie', 'z', 'dnia'), 38352.70893325243),\n",
       " (('o', 'której', 'mowa'), 36304.48245822556),\n",
       " (('zastępuje', 'się', 'wyrazami'), 31100.75623494178)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_top_10_LLR = list(LLR_trigrams.keys())[:10]\n",
    "list(LLR_trigrams.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_pmi = {}\n",
    "total_trigram_occurances = sum(trigrams.values())\n",
    "\n",
    "for trigram, freq in trigrams.items():\n",
    "    t1, t2, t3 = trigram\n",
    "    p1 = single_grams[t1]/total_single_occurances\n",
    "    p2 = single_grams[t2]/total_single_occurances\n",
    "    p3 = single_grams[t3]/total_single_occurances\n",
    "    p1p2p3 = freq/total_trigram_occurances\n",
    "    pmi = log(p1p2p3/(p1 * p2 * p3))\n",
    "    trigram_pmi[trigram] = (freq, pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('piłce', 'nożnej', 'uefa'), (9, 25.219350097730103)),\n",
       " (('profilem', 'zaufanym', 'epuap'), (8, 25.200992842211733)),\n",
       " (('religijne', 'uroczystości', 'pogrzebowe'), (6, 25.160407562096655)),\n",
       " (('finałowego', 'turnieju', 'mistrzostw'), (6, 25.142058423428455)),\n",
       " (('potwierdzonym', 'profilem', 'zaufanym'), (11, 24.88345780661027)),\n",
       " (('turnieju', 'mistrzostw', 'europy'), (6, 24.879694158960966)),\n",
       " (('grożącą', 'jemu', 'samemu'), (5, 24.27739161910737)),\n",
       " (('bankowemu', 'funduszowi', 'gwarancyjnemu'), (5, 24.210349967751682)),\n",
       " (('komunalne', 'osady', 'ściekowe'), (5, 24.179578309084928)),\n",
       " (('konfesyjne', 'nauczanie', 'religii'), (5, 24.15710545323287))]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_pmi = {k: v for k,v in sorted(trigram_pmi.items(), key=lambda item: item[1][1], reverse=True) if v[0] >= 5}\n",
    "\n",
    "trigram_top_10_pmi = list(trigram_pmi.keys())[:10]\n",
    "list(trigram_pmi.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 11\n",
    "top_10_bigrams = bigram_top_10_pmi + bigram_top_10_LLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('kołowe', 'jednoosiowe'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('automatyki', 'grzewczej'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('prefabrykatów', 'wnętrzowe'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('gołe', 'aluminiowe'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('polistyrenu', 'spienionego'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('objaśnieniem', 'figur'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('wkładzie', 'wnoszonym'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('doktorem', 'habilitowanym'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('naruszonymi', 'plombami'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('zaniedbanej', 'wychowawczo'): ((1, 15.232429554616882), 31.12486567648942),\n",
       " ('mowa', 'w'): ((27728, 2.980853838524479), 162056.43970866656),\n",
       " ('których', 'mowa'): ((13019, 4.640397578633193), 103860.60989464173),\n",
       " ('o', 'których'): ((12609, 3.801201625359062), 81588.40541168801),\n",
       " ('którym', 'mowa'): ((8722, 4.65931982435661), 67846.84419746423),\n",
       " ('dodaje', 'się'): ((7995, 4.4806066366680755), 62515.67442178589),\n",
       " ('do', 'spraw'): ((8198, 4.034401646575504), 57437.651725128424),\n",
       " ('o', 'którym'): ((8533, 3.830215285440522), 53202.142924775384),\n",
       " ('i', 'nr'): ((7898, 2.0893421415155338), 51618.30513495073),\n",
       " ('z', 'dnia'): ((9023, 3.241389775616099), 47165.64226194411),\n",
       " ('na', 'podstawie'): ((5888, 4.260335001891556), 45750.135696047284)}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key -> freq -> pmi -> LLR\n",
    "{k: (bigram_pmi[k], LLR_bigrams[k]) for k in top_10_bigrams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_triagrams = trigram_top_10_pmi + trigram_top_10_LLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('piłce', 'nożnej', 'uefa'): ((9, 25.219350097730103), 234.0720551123133),\n",
       " ('profilem', 'zaufanym', 'epuap'): ((8, 25.200992842211733),\n",
       "  215.72783421000346),\n",
       " ('religijne', 'uroczystości', 'pogrzebowe'): ((6, 25.160407562096655),\n",
       "  146.12663928095893),\n",
       " ('finałowego', 'turnieju', 'mistrzostw'): ((6, 25.142058423428455),\n",
       "  165.24806621257213),\n",
       " ('potwierdzonym', 'profilem', 'zaufanym'): ((11, 24.88345780661027),\n",
       "  278.4573757476447),\n",
       " ('turnieju', 'mistrzostw', 'europy'): ((6, 24.879694158960966),\n",
       "  159.50643775653444),\n",
       " ('grożącą', 'jemu', 'samemu'): ((5, 24.27739161910737), 125.74743292941659),\n",
       " ('bankowemu', 'funduszowi', 'gwarancyjnemu'): ((5, 24.210349967751682),\n",
       "  131.15416554098505),\n",
       " ('komunalne', 'osady', 'ściekowe'): ((5, 24.179578309084928),\n",
       "  110.03825080790341),\n",
       " ('konfesyjne', 'nauczanie', 'religii'): ((5, 24.15710545323287),\n",
       "  139.52993978117863),\n",
       " ('których', 'mowa', 'w'): ((12545, 7.608131662525183), 102495.7504384144),\n",
       " ('o', 'których', 'mowa'): ((11712, 8.673299353198884), 92046.18649791507),\n",
       " ('którym', 'mowa', 'w'): ((8463, 7.6339967086128695), 68036.21581825346),\n",
       " ('o', 'którym', 'mowa'): ((8045, 8.717219681642376), 62514.58015060082),\n",
       " ('minister', 'właściwy', 'do'): ((3835, 10.145206469171743),\n",
       "  48241.9150999556),\n",
       " ('właściwy', 'do', 'spraw'): ((4438, 9.925846403124522), 47786.77952740153),\n",
       " ('której', 'mowa', 'w'): ((5026, 7.570228778916645), 38775.47991226523),\n",
       " ('ustawie', 'z', 'dnia'): ((3523, 9.050639563523132), 38352.70893325243),\n",
       " ('o', 'której', 'mowa'): ((4718, 8.640865234053857), 36304.48245822556),\n",
       " ('zastępuje', 'się', 'wyrazami'): ((2340, 10.97331498717135),\n",
       "  31100.75623494178)}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key -> freq -> pmi -> LLR\n",
    "{k: (trigram_pmi[k], LLR_trigrams[k]) for k in top_10_triagrams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zad 12\n",
    "#Why do we have to filter the bigrams, rather than the token sequence?\n",
    "Przykład: ponad 100 zł, filtrując sekwencję tokenów dostaniemy tokeny: ponad, złotych, z czego uzyskamy bigram (ponad zł), \n",
    "wyrywany z kontektu i bez sensu (bez uwzględnienia kolejności słów).\n",
    "Natomiast jeśli najpierw podzielimy zdanie na uzyskamy 2 bigramy: (ponad 100), (100 zł), które potem zostaną odfiltrowane, \n",
    "nie uzyskamy efektu popisanego wyżej.\n",
    "\n",
    "#Which measure (PMI, PMI with filtering, LLR) works better for the bigrams and which for the trigrams?\n",
    "Obie metody znajdują inne wyrażenia. W przypadku trigramów PMI daje bardziej ciekawe resultaty, natomiast LLR znajduje znacznie \n",
    "popularniejsze wyrażenia (podobnie jak zwykła frequency lista). Rozważając bigarmy, tendencja jest ta sama. PMI zwrócił \n",
    "zaskakujące, rzadko występujące wyrażenia.\n",
    "Ze względu na całkiem inne działanie trudno dokonać porównania. \n",
    "\n",
    "#What types of expressions are discovered by the methods.\n",
    "LLR znajduje powrzechnie wsytępujące wyrażenia np. \"o którym mowa\", natomiast PMI znajduje utarte zwroty, nazwy własne \n",
    "(np. \"profilem zaufanym epuap\").\n",
    "\n",
    "#Can you devise a different type of filtering that would yield better results?\n",
    "Usunięcie przyimków 'w', 'na', 'do' i na odfiltrowanych bigramach użycie LLR mogłoby dać ciekawe resultaty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
